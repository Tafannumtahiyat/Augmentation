{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ohi_ex12_vgg16_withaug.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oNpeyaYFbhG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8b6e1f6e-5ca2-44e3-b1a3-ac3ccdae5895"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils import to_categorical\n",
        "import cv2\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.models import load_model\n",
        "import imutils"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Z-iO2N8Fkv7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "1cae7490-92e3-409c-a762-c25c22fe434d"
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "He3DqFylF6BM"
      },
      "source": [
        "x = np.load('./drive/My Drive/lict/numta_x.npy')/255.0\n",
        "y = np.load('./drive/My Drive/lict/numta_y.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQRK2dk6GbKK"
      },
      "source": [
        "x = x.reshape(-1,64,64,1)\n",
        "from keras.utils import to_categorical\n",
        "y = to_categorical(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17VSxYT1GfD6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c96cc1a6-a717-4898-d4d2-0640e69f0255"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(55267, 64, 64, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bn1p7BwiGlMj"
      },
      "source": [
        "from keras import Sequential\n",
        "from keras.layers import Conv2D, MaxPool2D, Flatten, Dropout, Dense,ZeroPadding2D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-L8QX6K3Gwpj"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(input_shape=(64,64,1),filters=64,kernel_size=(2,2),padding=\"same\", activation=\"relu\"))\n",
        "\n",
        "\n",
        "model.add(Conv2D(filters=64,kernel_size=(2,2),padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Conv2D(filters=128, kernel_size=(2,2), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=128, kernel_size=(2,2), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Conv2D(filters=256, kernel_size=(2,2), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=256, kernel_size=(2,2), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=256, kernel_size=(2,2), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(units=64,activation=\"relu\"))\n",
        "model.add(Dense(units=10, activation=\"softmax\"))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZpLyWNgHPCH"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y,shuffle=True, test_size=0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UP2AP4ScHQtC"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(rotation_range=5, width_shift_range=0.2, height_shift_range=0.2,  zoom_range=0.2)\n",
        "\n",
        "datagen.fit(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2VUqZUhIqDq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        },
        "outputId": "c676c978-a3d8-4262-b3a0-49ad4f118579"
      },
      "source": [
        "history= model.fit(datagen.flow(x_train, y_train,batch_size=250),validation_data=(x_test, y_test),epochs=20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "219/219 [==============================] - 56s 257ms/step - loss: 2.3030 - accuracy: 0.0988 - val_loss: 2.3024 - val_accuracy: 0.1230\n",
            "Epoch 2/20\n",
            "219/219 [==============================] - 55s 252ms/step - loss: 2.3026 - accuracy: 0.0998 - val_loss: 2.3026 - val_accuracy: 0.0904\n",
            "Epoch 3/20\n",
            "219/219 [==============================] - 55s 252ms/step - loss: 2.3026 - accuracy: 0.1003 - val_loss: 2.3026 - val_accuracy: 0.0904\n",
            "Epoch 4/20\n",
            "219/219 [==============================] - 55s 251ms/step - loss: 2.3026 - accuracy: 0.0985 - val_loss: 2.3026 - val_accuracy: 0.1085\n",
            "Epoch 5/20\n",
            "219/219 [==============================] - 55s 251ms/step - loss: 2.3026 - accuracy: 0.0983 - val_loss: 2.3027 - val_accuracy: 0.0904\n",
            "Epoch 6/20\n",
            "219/219 [==============================] - 55s 251ms/step - loss: 2.3026 - accuracy: 0.0991 - val_loss: 2.3026 - val_accuracy: 0.0904\n",
            "Epoch 7/20\n",
            "219/219 [==============================] - 55s 251ms/step - loss: 2.3026 - accuracy: 0.0972 - val_loss: 2.3027 - val_accuracy: 0.0904\n",
            "Epoch 8/20\n",
            "219/219 [==============================] - 55s 252ms/step - loss: 2.3026 - accuracy: 0.0998 - val_loss: 2.3027 - val_accuracy: 0.0904\n",
            "Epoch 9/20\n",
            "219/219 [==============================] - 55s 252ms/step - loss: 2.3026 - accuracy: 0.0998 - val_loss: 2.3024 - val_accuracy: 0.0904\n",
            "Epoch 10/20\n",
            "219/219 [==============================] - 55s 251ms/step - loss: 2.3026 - accuracy: 0.0996 - val_loss: 2.3025 - val_accuracy: 0.0904\n",
            "Epoch 11/20\n",
            "219/219 [==============================] - 55s 251ms/step - loss: 2.3026 - accuracy: 0.0987 - val_loss: 2.3027 - val_accuracy: 0.0904\n",
            "Epoch 12/20\n",
            "219/219 [==============================] - 55s 251ms/step - loss: 2.3026 - accuracy: 0.0984 - val_loss: 2.3024 - val_accuracy: 0.0904\n",
            "Epoch 13/20\n",
            "219/219 [==============================] - 55s 251ms/step - loss: 2.3026 - accuracy: 0.0971 - val_loss: 2.3025 - val_accuracy: 0.0904\n",
            "Epoch 14/20\n",
            "219/219 [==============================] - 55s 251ms/step - loss: 2.3026 - accuracy: 0.0993 - val_loss: 2.3025 - val_accuracy: 0.0904\n",
            "Epoch 15/20\n",
            "219/219 [==============================] - 55s 252ms/step - loss: 2.3026 - accuracy: 0.1002 - val_loss: 2.3026 - val_accuracy: 0.0904\n",
            "Epoch 16/20\n",
            "219/219 [==============================] - 55s 251ms/step - loss: 2.3026 - accuracy: 0.0996 - val_loss: 2.3027 - val_accuracy: 0.0904\n",
            "Epoch 17/20\n",
            "219/219 [==============================] - 55s 251ms/step - loss: 2.3026 - accuracy: 0.1007 - val_loss: 2.3025 - val_accuracy: 0.0904\n",
            "Epoch 18/20\n",
            "219/219 [==============================] - 55s 251ms/step - loss: 2.3026 - accuracy: 0.0978 - val_loss: 2.3025 - val_accuracy: 0.0904\n",
            "Epoch 19/20\n",
            "219/219 [==============================] - 55s 251ms/step - loss: 2.3026 - accuracy: 0.0997 - val_loss: 2.3027 - val_accuracy: 0.0904\n",
            "Epoch 20/20\n",
            "  1/219 [..............................] - ETA: 54s - loss: 2.3027 - accuracy: 0.0960"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sLY7ueSvJbx"
      },
      "source": [
        "model.save('weight.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mh8IIgopvBca"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model acc')\n",
        "plt.ylabel('acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYKiQGljI0Bj"
      },
      "source": [
        "def segment(image, height=64):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    gray = cv2.GaussianBlur(gray, (7, 7), 0)\n",
        " \n",
        "    # threshold the image\n",
        "    ret,thresh1 = cv2.threshold(gray ,100,255,cv2.THRESH_BINARY_INV)\n",
        " \n",
        "    # dilate the white portions\n",
        "    dilate = cv2.dilate(thresh1, None, iterations=2)\n",
        " \n",
        "    # find contours in the image\n",
        "    cnts = cv2.findContours(dilate.copy(), cv2.RETR_EXTERNAL,\n",
        "        cv2.CHAIN_APPROX_SIMPLE)\n",
        "    cnts = cnts[1] if imutils.is_cv2() else cnts[0]\n",
        " \n",
        "    orig = image.copy()\n",
        "    i = 0\n",
        "    t = 0\n",
        "    c=0\n",
        "    x_all = []\n",
        "    w_all = []\n",
        "    lines = []\n",
        "    parts = []\n",
        " \n",
        "    for cnt in cnts:\n",
        "        # Check the area of contour, if it is very small ignore it\n",
        "        if(cv2.contourArea(cnt) < 100):\n",
        "            continue\n",
        " \n",
        "        # Filtered countours are detected\n",
        "        x,y,w,h = cv2.boundingRect(cnt)\n",
        "        x_all.append(x)\n",
        "        w_all.append(w)\n",
        "        i = i + 1\n",
        " \n",
        "    comb = np.zeros((2,len(x_all)))\n",
        "    comb[0,:]=x_all\n",
        "    comb[1,:]=w_all\n",
        "    comb = comb.T\n",
        "    comb = comb[comb[:,0].argsort()]\n",
        " \n",
        "    x_all = comb[:,0]\n",
        "    w_all = comb[:,1]\n",
        " \n",
        " \n",
        "    for i, item in enumerate (x_all):\n",
        "        if i < len(x_all)-1:\n",
        "            lines.append((item+w_all[i]+x_all[i+1])/2)\n",
        " \n",
        " \n",
        "    for i in range(len(lines)):\n",
        "        parts.append(cv2.resize(image[:,t:int(lines[i]),:],(height,height)))\n",
        "        t = int(lines[i])\n",
        "        if i == len(lines)-1:\n",
        "            parts.append(cv2.resize(image[:,t:,:],(height,height)))\n",
        "   \n",
        "    return parts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Me4M3sLzxeXB"
      },
      "source": [
        "img=cv2.imread('test1.jpg')\n",
        "\n",
        "a=segment(img)\n",
        "L=np.array(a)\n",
        "L.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YTUJk_AORDr"
      },
      "source": [
        "\n",
        "result=[]\n",
        "s=\"\"\n",
        "for i in range (0,4):\n",
        "    img1=(cv2.resize(L[i],(64,64),0))\n",
        "    p=np.argmax(model.predict(np.reshape(img1,(-1,64,64,1))))\n",
        "    s=s+str(p)\n",
        "   \n",
        "plt.imshow(img)\n",
        "plt.title(s)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}